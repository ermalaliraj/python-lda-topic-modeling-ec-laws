{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ermal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ermal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from datetime import timedelta\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import ktrain\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "np.set_printoptions(edgeitems=30, linewidth=1000)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "data_dir = \"C:/Users/admin/Documents/Projects/accademic/python-lda-topic-modeling-ec-laws/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string_utf8(document):\n",
    "    return document.decode('utf-8')\n",
    "\n",
    "def get_file_content(filepath):\n",
    "    tree = ET.parse(filepath)\n",
    "    document = ET.tostring(tree.getroot(), encoding='utf-8', method='text')\n",
    "    document = to_string_utf8(document)\n",
    "    document = re.sub('[ \\t\\n]+', ' ', document)\n",
    "    return document\n",
    "\n",
    "def lemmatization(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stopwordsList = set(stopwords.words(\"english\"))\n",
    "    words = text.lower().split(\" \")\n",
    "    cleaned_text = \"\"\n",
    "    for word in words:\n",
    "        if word in stopwordsList: continue\n",
    "        cleaned_text += lemmatizer.lemmatize(word) + \" \"\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.29 s\n"
     ]
    }
   ],
   "source": [
    " %%time\n",
    "year = \"2016\"\n",
    "documents = []\n",
    "for doc in os.listdir(data_dir):\n",
    "    # if doc.endswith(\".xml\"):\n",
    "    if doc.startswith(\"reg_\" + year) and doc.endswith(\".xml\"):\n",
    "        try:\n",
    "            documents.append([doc, lemmatization(get_file_content(os.path.join(data_dir, doc)))])\n",
    "        except:\n",
    "            pass\n",
    "documents = np.array(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_topics automatically set to 11\n",
      "lang: en\n",
      "preprocessing texts...\n",
      "fitting model...\n",
      "iteration: 1 of max_iter: 5\n",
      "iteration: 2 of max_iter: 5\n",
      "iteration: 3 of max_iter: 5\n",
      "iteration: 4 of max_iter: 5\n",
      "iteration: 5 of max_iter: 5\n",
      "done.\n",
      "Wall time: 5.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = ktrain.text.get_topic_model(documents[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.build(documents[:, 1], threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic:5 | count:63 | fishing product stock vessel price investigation import industry country quota\n",
      "topic:0 | count:58 | food substance use directive list health claim product efsa animal\n",
      "topic:9 | count:46 | agency national border data decision paragraph act procedure service directive\n",
      "topic:3 | count:29 | relevant power requirement operator product plant module paragraph point demand\n",
      "topic:4 | count:23 | benchmark law paragraph fishing competent vessel decision data court property\n",
      "topic:8 | count:15 | data processing personal body supervisory subject conformity protection right decision\n",
      "topic:2 | count:10 | animal disease point health product competent establishment paragraph listed engine\n",
      "topic:1 | count:3 | data europol management personal board agency border director national right\n",
      "topic:6 | count:2 | restriction agency benchmark safety directive paragraph relevant assessment rac competent\n"
     ]
    }
   ],
   "source": [
    "model.print_topics(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reducing to 2 dimensions...[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 249 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 249 samples in 0.005s...\n",
      "[t-SNE] Computed conditional probabilities for sample 249 / 249\n",
      "[t-SNE] Mean sigma: 0.006865\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 52.884964\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.187976\n",
      "done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"6dd77aec-fd63-45ab-b539-581e65f858f8\" data-root-id=\"1004\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {},
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1004"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "topics = model.get_doctopics()\n",
    "model.visualize_documents(doc_topics=topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Topic found for document  reg_2016_nr-003_seq-0002_akn.xml (similarity threshold 0.25)\n"
     ]
    }
   ],
   "source": [
    "topic_to_document = defaultdict(list)\n",
    "for doc in documents:\n",
    "    pred = model.predict([doc[1]])[0]\n",
    "    found = False\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] >= 0.25:  # 0.25 is threshold value of similarity. Less than this is talking for different topic\n",
    "            topic_to_document[i].append(doc[0])\n",
    "            found = True\n",
    "\n",
    "    if not found:\n",
    "        print(\"No Topic found for document \", doc[0], \"(similarity threshold 0.25)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 documents are spread as follow:\n",
      "Topic 0 is found in 70 documents\n",
      "Topic 1 is found in 4 documents\n",
      "Topic 2 is found in 13 documents\n",
      "Topic 3 is found in 39 documents\n",
      "Topic 4 is found in 35 documents\n",
      "Topic 5 is found in 68 documents\n",
      "Topic 6 is found in 4 documents\n",
      "Topic 7 is found in 0 documents\n",
      "Topic 8 is found in 18 documents\n",
      "Topic 9 is found in 55 documents\n"
     ]
    }
   ],
   "source": [
    "print(len(documents), \"documents are spread as follow:\")\n",
    "for topic_doc in range(len(topic_to_document)):\n",
    "    print(\"Topic\", topic_doc, \"is found in\", len(topic_to_document[topic_doc]), \"documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In order to ensure a consistent level of protection for natural persons throughout the Union and to prevent divergences hampering the free movement of personal data within the internal market, a Regulation is necessary to provide legal certainty and transparency for economic operators, including micro, small and medium-sized enterprises, and to provide natural persons in all Member States with the same level of legally enforceable rights and obligations and responsibilities for controllers and processors, to ensure consistent monitoring of the processing of personal data, and equivalent sanctions in all Member States as well as effective cooperation between the supervisory authorities of different Member States. The proper functioning of the internal market requires that the free movement of personal data within the Union is not restricted or prohibited for reasons connected with the protection of natural persons with regard to the processing of personal data. To take account of the specific situation of micro, small and medium-sized enterprises, this Regulation includes a derogation for organisations with fewer than 250 employees with regard to record-keeping. In addition, the Union institutions and bodies, and Member States and their supervisory authorities, are encouraged to take account of the specific needs of micro, small and medium-sized enterprises in the application of this Regulation. The notion of micro, small and medium-sized enterprises should draw from Article 2 of the Annex to Commission Recommendation 2003/361/EC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.argmax(model.predict([lemmatization(text)]))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted text is similar to Topic 8  - \" data processing personal body supervisory subject conformity protection right decision \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Inserted text is similar to Topic\", pred, \" - \\\"\", topics[pred], \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 documents containing Topic 8 :  ['reg_2016_679_akn_nr119seq0001.xml', 'reg_2016_nr-010_seq-0001_akn.xml', 'reg_2016_nr-012_seq-0001_akn.xml', 'reg_2016_nr-040_seq-0001_akn.xml', 'reg_2016_nr-068_seq-0001_akn.xml', 'reg_2016_nr-081_seq-0001_akn.xml', 'reg_2016_nr-081_seq-0002_akn.xml', 'reg_2016_nr-081_seq-0003_akn.xml', 'reg_2016_nr-085_seq-0001_akn.xml', 'reg_2016_nr-096_seq-0001_akn.xml', 'reg_2016_nr-153_seq-0001_akn.xml', 'reg_2016_nr-162_seq-0001_akn.xml', 'reg_2016_nr-193_seq-0002_akn.xml', 'reg_2016_nr-255_seq-0001_akn.xml', 'reg_2016_nr-259_seq-0001_akn.xml', 'reg_2016_nr-268_seq-0006_akn.xml', 'reg_2016_nr-317_seq-0001_akn.xml', 'reg_2016_nr-336_seq-0001_akn.xml']\n"
     ]
    }
   ],
   "source": [
    "print(len(topic_to_document[pred]), \"documents containing Topic\", pred, \": \", topic_to_document[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
